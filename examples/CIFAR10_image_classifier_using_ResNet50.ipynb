{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 image classifier using ResNet50",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f33a89ec3394dc589a9d3c444f7d7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_867b11c36d864838922ce5b283461fa3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_846d171166034b459848426f2ea275ab",
              "IPY_MODEL_91cfe680f2364cf6be10a420318ba1b0",
              "IPY_MODEL_452a20c20e2d4677a7fad466c017e15e"
            ]
          }
        },
        "867b11c36d864838922ce5b283461fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "846d171166034b459848426f2ea275ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17ab023b06f64c7c95edae3321197700",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07c214ff815a4cc8af6ce67f70779307"
          }
        },
        "91cfe680f2364cf6be10a420318ba1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f009996ec474475c864589333db04c71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ea27fffd503460ebad4d971aef8eec0"
          }
        },
        "452a20c20e2d4677a7fad466c017e15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_027c190a918b4ffdb77e60eb94e54761",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:12&lt;00:00, 16465800.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16a302c251514d95995318c3bece2cea"
          }
        },
        "17ab023b06f64c7c95edae3321197700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07c214ff815a4cc8af6ce67f70779307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f009996ec474475c864589333db04c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ea27fffd503460ebad4d971aef8eec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "027c190a918b4ffdb77e60eb94e54761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16a302c251514d95995318c3bece2cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhrbvVEh2iJd"
      },
      "source": [
        "# CIFAR-10 Image Classifier using Resnet50(Transfer Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP7LvCpG23a2",
        "outputId": "797498f4-3ef1-4fcb-af6f-c00a0cbfe3aa"
      },
      "source": [
        "!pip install ColossalAI deepspeed"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ColossalAI\n",
            "  Downloading colossalai-0.0.1b0-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting deepspeed\n",
            "  Downloading deepspeed-0.5.8.tar.gz (517 kB)\n",
            "\u001b[K     |████████████████████████████████| 517 kB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (4.62.3)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (5.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.19.5)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->ColossalAI) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9->ColossalAI) (7.1.2)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.0.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting triton\n",
            "  Downloading triton-1.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2 MB 221 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ColossalAI) (3.0.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->ColossalAI) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->ColossalAI) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from triton->deepspeed) (3.4.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.8-py3-none-any.whl size=532154 sha256=833d544e3f1c979f4c7e354f0c163785b0cd1fef7b1db595b3507f238cf63702\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/c6/82/cabd9a300c582a221591fd2c8c997e1f03f601e748aad44e4e\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: triton, tensorboardX, ninja, hjson, deepspeed, ColossalAI\n",
            "Successfully installed ColossalAI-0.0.1b0 deepspeed-0.5.8 hjson-3.0.2 ninja-1.10.2.3 tensorboardX-2.4.1 triton-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVKEurtS4SFS",
        "outputId": "d61b78b3-1153-4c3b-9f9a-f07d4075c430"
      },
      "source": [
        "import colossalai\n",
        "from colossalai.engine import Engine, NoPipelineSchedule\n",
        "from colossalai.trainer import Trainer\n",
        "from colossalai.context import Config\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
            "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
            "apex is required for mixed precision training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb3a662tC2J9"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpFfhNBD7NSn"
      },
      "source": [
        "First, we should initialize distributed environment. Though we just use single GPU in this example, we still need initialize distributed environment for compatibility. We just consider the simplest case here, so we just set the number of parallel processes to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yF7Lc-K7NAS",
        "outputId": "4cf53b7b-7123-440a-a38e-99e721be0e11"
      },
      "source": [
        "parallel_cfg = Config(dict(parallel=dict(\n",
        "    data=dict(size=1),\n",
        "    pipeline=dict(size=1),\n",
        "    tensor=dict(size=1, mode=None),\n",
        ")))\n",
        "colossalai.init_dist(config=parallel_cfg,\n",
        "          local_rank=0,\n",
        "          world_size=1,\n",
        "          host='127.0.0.1',\n",
        "          port=8888,\n",
        "          backend='nccl')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,971 INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,973 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,980 INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,984 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,987 INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-06 04:24:56,991 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process rank 0 is bound to device 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppjmMxc_81TK"
      },
      "source": [
        "Load and normalize the CIFAR10 training and test datasets using `colossalai.nn.data`. Note that we have wrapped `torchvision.transforms`, so that we can simply use the config dict to use them.\n",
        "\n",
        "Also doing some preprocessing on the input for better training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyGhyD47-dUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "4f33a89ec3394dc589a9d3c444f7d7ff",
            "867b11c36d864838922ce5b283461fa3",
            "846d171166034b459848426f2ea275ab",
            "91cfe680f2364cf6be10a420318ba1b0",
            "452a20c20e2d4677a7fad466c017e15e",
            "17ab023b06f64c7c95edae3321197700",
            "07c214ff815a4cc8af6ce67f70779307",
            "f009996ec474475c864589333db04c71",
            "1ea27fffd503460ebad4d971aef8eec0",
            "027c190a918b4ffdb77e60eb94e54761",
            "16a302c251514d95995318c3bece2cea"
          ]
        },
        "outputId": "c9953d6e-d98f-4d41-f637-a24c3f2cd6be"
      },
      "source": [
        "\n",
        "transform_cfg = [\n",
        "    dict(type='ToTensor'),\n",
        "    dict(type='Normalize',\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010]),\n",
        "]\n",
        "transform_cfg1 = [\n",
        "    dict(type='RandomCrop',size=32,padding_mode=\"reflect\"),\n",
        "    dict(type='RandomHorizontalFlip'),\n",
        "    # dict(type='RandomResizedCrop',size=256,scale=(0.5,0.9), ratio=(1, 1)),\n",
        "    # dict(type='ColorJitter',brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    dict(type='ToTensor'),\n",
        "    dict(type='Normalize',\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010]),\n",
        "]\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = colossalai.nn.data.CIFAR10Dataset(transform_cfg1, root='./data', train=True,download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = colossalai.nn.data.CIFAR10Dataset(transform_cfg, root='./data', train=False,download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f33a89ec3394dc589a9d3c444f7d7ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvPbfLLR9NzC"
      },
      "source": [
        "We just define a Resnet50 Convolutional Neural Network here and replace last layer with a fully connected layer with appropriate inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ_y7lBG09LS"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "class Cifar(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet50(pretrained=pretrained)\n",
        "        # Replace last layer\n",
        "        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "model = Cifar(10).cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgsszAmM9dYZ"
      },
      "source": [
        "Define a Loss function and optimizer. And then we use them to initialize `Engine` and `Trainer`. We provide various training / evaluating hooks. In this case, we just use the simplest hooks which can compute and print loss and accuracy. Using SGD optimizer with lr = .001 and CrossEntropyLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtaDoCax1BCf",
        "outputId": "8697c5e2-28f4-4cf0-fb37-90b6d5ba7cc1"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "schedule = NoPipelineSchedule()\n",
        "engine = Engine(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=None,\n",
        "        schedule=schedule\n",
        "    )\n",
        "trainer = Trainer(engine=engine,\n",
        "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
        "          verbose=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - rank_0 - 2021-12-06 04:38:37,361 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
            "colossalai - rank_0 - 2021-12-06 04:38:37,365 INFO: build LogMetricByEpochHook for train, priority = 1\n",
            "colossalai - rank_0 - 2021-12-06 04:38:37,366 INFO: build LossHook for train, priority = 10\n",
            "colossalai - rank_0 - 2021-12-06 04:38:37,370 INFO: build AccuracyHook for train, priority = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JR2TuvH99Ik"
      },
      "source": [
        "Then we set training configs. We train our model for 5 epochs and it will be evaluated every 1 epoch. Set `display_progress` to `True` to display the training / evaluating progress bar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-J3IP-J1sfx",
        "outputId": "4557bc3f-efb5-4536-e3df-a9c64a5c99ef"
      },
      "source": [
        "%%time\n",
        "num_epochs = 5\n",
        "test_interval = 1\n",
        "trainer.fit(\n",
        "        train_dataloader=trainloader,\n",
        "        test_dataloader=testloader,\n",
        "        max_epochs=num_epochs,\n",
        "        display_progress=True,\n",
        "        test_interval=test_interval\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 0 train]: 100%|██████████| 391/391 [01:02<00:00,  6.23it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:39:51,454 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 1.10606\n",
            "[Epoch 0 val]: 100%|██████████| 79/79 [00:04<00:00, 18.39it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:39:55,958 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.70309, Accuracy = 0.75960\n",
            "[Epoch 1 train]: 100%|██████████| 391/391 [01:02<00:00,  6.24it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:40:58,868 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.59152\n",
            "[Epoch 1 val]: 100%|██████████| 79/79 [00:04<00:00, 18.56it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:41:03,326 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.58491, Accuracy = 0.80020\n",
            "[Epoch 2 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:42:06,253 INFO: Training - Epoch 3 - LogMetricByEpochHook: Loss = 0.44258\n",
            "[Epoch 2 val]: 100%|██████████| 79/79 [00:04<00:00, 18.24it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:42:10,747 INFO: Testing - Epoch 3 - LogMetricByEpochHook: Loss = 0.54638, Accuracy = 0.81690\n",
            "[Epoch 3 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:43:13,632 INFO: Training - Epoch 4 - LogMetricByEpochHook: Loss = 0.34467\n",
            "[Epoch 3 val]: 100%|██████████| 79/79 [00:04<00:00, 18.27it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:43:18,147 INFO: Testing - Epoch 4 - LogMetricByEpochHook: Loss = 0.52483, Accuracy = 0.82670\n",
            "[Epoch 4 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:44:20,982 INFO: Training - Epoch 5 - LogMetricByEpochHook: Loss = 0.27311\n",
            "[Epoch 4 val]: 100%|██████████| 79/79 [00:04<00:00, 18.26it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:44:25,520 INFO: Testing - Epoch 5 - LogMetricByEpochHook: Loss = 0.52902, Accuracy = 0.83180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 48s, sys: 39.5 s, total: 5min 28s\n",
            "Wall time: 5min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLHEgk-g-NU6"
      },
      "source": [
        "Same thing with lr= 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fxsFFBZDoZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59017206-57ea-411c-f887-b54e2990d2cc"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "schedule = NoPipelineSchedule()\n",
        "engine = Engine(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=None,\n",
        "        schedule=schedule\n",
        "    )\n",
        "trainer = Trainer(engine=engine,\n",
        "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
        "          verbose=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - rank_0 - 2021-12-06 04:44:45,603 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
            "colossalai - rank_0 - 2021-12-06 04:44:45,608 INFO: build LogMetricByEpochHook for train, priority = 1\n",
            "colossalai - rank_0 - 2021-12-06 04:44:45,611 INFO: build LossHook for train, priority = 10\n",
            "colossalai - rank_0 - 2021-12-06 04:44:45,614 INFO: build AccuracyHook for train, priority = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWfWMgHm-WF-"
      },
      "source": [
        "5 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEkHb36gJqua",
        "outputId": "b56b1cae-e2b2-4168-d24d-82e1226274fb"
      },
      "source": [
        "%%time\n",
        "num_epochs = 5\n",
        "test_interval = 1\n",
        "trainer.fit(\n",
        "        train_dataloader=trainloader,\n",
        "        test_dataloader=testloader,\n",
        "        max_epochs=num_epochs,\n",
        "        display_progress=True,\n",
        "        test_interval=test_interval\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6caf3773b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6caf3773b0>\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "[Epoch 0 train]:   0%|          | 0/391 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6caf3773b0>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6caf3773b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "[Epoch 0 train]: 100%|██████████| 391/391 [01:02<00:00,  6.21it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:45:56,867 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.18971\n",
            "[Epoch 0 val]: 100%|██████████| 79/79 [00:04<00:00, 18.26it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:46:01,382 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.51806, Accuracy = 0.83790\n",
            "[Epoch 1 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:47:04,274 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.16910\n",
            "[Epoch 1 val]: 100%|██████████| 79/79 [00:04<00:00, 18.38it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:47:08,755 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.52548, Accuracy = 0.83780\n",
            "[Epoch 2 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:48:11,662 INFO: Training - Epoch 3 - LogMetricByEpochHook: Loss = 0.15415\n",
            "[Epoch 2 val]: 100%|██████████| 79/79 [00:04<00:00, 18.29it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:48:16,156 INFO: Testing - Epoch 3 - LogMetricByEpochHook: Loss = 0.52996, Accuracy = 0.83870\n",
            "[Epoch 3 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:49:19,041 INFO: Training - Epoch 4 - LogMetricByEpochHook: Loss = 0.14422\n",
            "[Epoch 3 val]: 100%|██████████| 79/79 [00:04<00:00, 18.50it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:49:23,504 INFO: Testing - Epoch 4 - LogMetricByEpochHook: Loss = 0.53418, Accuracy = 0.83950\n",
            "[Epoch 4 train]: 100%|██████████| 391/391 [01:02<00:00,  6.25it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:50:26,390 INFO: Training - Epoch 5 - LogMetricByEpochHook: Loss = 0.13387\n",
            "[Epoch 4 val]: 100%|██████████| 79/79 [00:04<00:00, 18.15it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:50:30,908 INFO: Testing - Epoch 5 - LogMetricByEpochHook: Loss = 0.53999, Accuracy = 0.83860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 48s, sys: 39.6 s, total: 5min 28s\n",
            "Wall time: 5min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPdg2yDt-ZNP"
      },
      "source": [
        "We are already at 83.8% accuracy.\n",
        "Finally using Adam Optimizer with lr=1e-4 and weight decay= 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzyKjw_JJ_d6",
        "outputId": "dd6259e7-7912-4016-d486-e0c07675cd9e"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "schedule = NoPipelineSchedule()\n",
        "engine = Engine(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=None,\n",
        "        schedule=schedule\n",
        "    )\n",
        "trainer = Trainer(engine=engine,\n",
        "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
        "          verbose=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - rank_0 - 2021-12-06 04:50:42,972 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
            "colossalai - rank_0 - 2021-12-06 04:50:42,975 INFO: build LogMetricByEpochHook for train, priority = 1\n",
            "colossalai - rank_0 - 2021-12-06 04:50:42,977 INFO: build LossHook for train, priority = 10\n",
            "colossalai - rank_0 - 2021-12-06 04:50:42,978 INFO: build AccuracyHook for train, priority = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdkOHXhE-1mS"
      },
      "source": [
        "5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uRr8aq9P7VW",
        "outputId": "81fd0eb7-45e4-4dbb-c1aa-4c1eff0517b1"
      },
      "source": [
        "%%time\n",
        "num_epochs = 5\n",
        "test_interval = 1\n",
        "trainer.fit(\n",
        "        train_dataloader=trainloader,\n",
        "        test_dataloader=testloader,\n",
        "        max_epochs=num_epochs,\n",
        "        display_progress=True,\n",
        "        test_interval=test_interval\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 0 train]: 100%|██████████| 391/391 [01:07<00:00,  5.80it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:52:12,838 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.34013\n",
            "[Epoch 0 val]: 100%|██████████| 79/79 [00:04<00:00, 18.52it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:52:17,290 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.51375, Accuracy = 0.83460\n",
            "[Epoch 1 train]: 100%|██████████| 391/391 [01:06<00:00,  5.84it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:53:24,492 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.26153\n",
            "[Epoch 1 val]: 100%|██████████| 79/79 [00:04<00:00, 18.42it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:53:28,980 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.50180, Accuracy = 0.84080\n",
            "[Epoch 2 train]: 100%|██████████| 391/391 [01:07<00:00,  5.83it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:54:36,236 INFO: Training - Epoch 3 - LogMetricByEpochHook: Loss = 0.20791\n",
            "[Epoch 2 val]: 100%|██████████| 79/79 [00:04<00:00, 18.46it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:54:40,701 INFO: Testing - Epoch 3 - LogMetricByEpochHook: Loss = 0.51911, Accuracy = 0.85010\n",
            "[Epoch 3 train]: 100%|██████████| 391/391 [01:07<00:00,  5.83it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:55:47,945 INFO: Training - Epoch 4 - LogMetricByEpochHook: Loss = 0.16166\n",
            "[Epoch 3 val]: 100%|██████████| 79/79 [00:04<00:00, 18.61it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:55:52,381 INFO: Testing - Epoch 4 - LogMetricByEpochHook: Loss = 0.51233, Accuracy = 0.85260\n",
            "[Epoch 4 train]: 100%|██████████| 391/391 [01:07<00:00,  5.83it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:56:59,635 INFO: Training - Epoch 5 - LogMetricByEpochHook: Loss = 0.14103\n",
            "[Epoch 4 val]: 100%|██████████| 79/79 [00:04<00:00, 18.41it/s]\n",
            "colossalai - rank_0 - 2021-12-06 04:57:04,091 INFO: Testing - Epoch 5 - LogMetricByEpochHook: Loss = 0.52139, Accuracy = 0.85290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 29s, sys: 1min 18s, total: 5min 47s\n",
            "Wall time: 5min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbNOc1ES-_Rv"
      },
      "source": [
        "We can see that 85.3% accuracy has been achieved in only 17 mins of training. This could be only possible due to the easy to implement code of colossalAI which let me train on a gpu without having to change my coding habits of normal pytorch code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtU0kZsVP-VZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rff5CIUdHobu"
      },
      "source": [
        "Refrences:\n",
        "[ColossalAI Cifar10 example](https://github.com/hpcaitech/ColossalAI/blob/main/examples/colossal_cifar_demo.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIw8zAXIH_bF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}