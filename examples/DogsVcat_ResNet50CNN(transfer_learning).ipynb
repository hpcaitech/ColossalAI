{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9E-WWpwL_wG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcbTmhFY-oVM"
   },
   "source": [
    "# Example of ColossalAI applied on an external dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX2kU5mFMMMw"
   },
   "source": [
    "Creating the dataset\n",
    "\n",
    "Kindly download the train.zip from https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "And create Train directory in Colab Notebooks directory\n",
    "or import dataset and change code accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4UW-2ntdI6O"
   },
   "source": [
    "Mounting the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkqlxsIAkGgY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = \"/content/drive/My Drive\"\n",
    "\n",
    "os.chdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OA7BA5XLO4Hg"
   },
   "source": [
    "unzipping train.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NT0EkNDkQY3"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/Colab Notebooks/train.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aNzFg8kIkru4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "train_df = pd.DataFrame(columns=[\"img_name\",\"label\"])\n",
    "train_df[\"img_name\"] = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Train/train/\")\n",
    "for idx, i in enumerate(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Train/train/\")):\n",
    "    if \"cat\" in i:\n",
    "        train_df[\"label\"][idx] = 0\n",
    "    if \"dog\" in i:\n",
    "        train_df[\"label\"][idx] = 1\n",
    "\n",
    "train_df.to_csv (r'train_csv.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyyBFTqwPNwS"
   },
   "source": [
    "created train.csv containg the image title along with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1c0jNo33k4VD"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0V5SOaKXk-kB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class CatsAndDogsDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(annotation_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations.iloc[index, 0]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
    "        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n",
    "       \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        # print(img.dtype)\n",
    "        # print(y_label.dtype)\n",
    "        img = np.asarray(np.copy(img), dtype='float32')\n",
    "        label = np.asarray(np.copy(y_label), dtype='float32')\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        # Load the data into PyTorch tensors\n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label)\n",
    "        targets = label.view(1)\n",
    "        return (img, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENo32tZNPdW1"
   },
   "source": [
    "Creating the custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPtAbM3Ak_uB",
    "outputId": "25a76651-7148-4127-d7ed-747babcefc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ColossalAI\n",
      "  Downloading colossalai-0.0.1b0-py3-none-any.whl (234 kB)\n",
      "\u001b[K     |████████████████████████████████| 234 kB 3.1 MB/s \n",
      "\u001b[?25hCollecting deepspeed\n",
      "  Downloading deepspeed-0.5.8.tar.gz (517 kB)\n",
      "\u001b[K     |████████████████████████████████| 517 kB 40.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (0.11.1+cu111)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (5.4.8)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 42.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (21.3)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.10.0+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->ColossalAI) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9->ColossalAI) (7.1.2)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 46.5 MB/s \n",
      "\u001b[?25hCollecting hjson\n",
      "  Downloading hjson-3.0.2-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
      "\u001b[?25hCollecting triton\n",
      "  Downloading triton-1.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.2 MB 241 kB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ColossalAI) (3.0.6)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->ColossalAI) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->ColossalAI) (1.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from triton->deepspeed) (3.4.0)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.5.8-py3-none-any.whl size=532154 sha256=002a7304298fc0c04b10469b72bbe44e50d2eb578e4c607c916af6adba4211de\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/c6/82/cabd9a300c582a221591fd2c8c997e1f03f601e748aad44e4e\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: triton, tensorboardX, ninja, hjson, deepspeed, ColossalAI\n",
      "Successfully installed ColossalAI-0.0.1b0 deepspeed-0.5.8 hjson-3.0.2 ninja-1.10.2.3 tensorboardX-2.4.1 triton-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ColossalAI deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shzs8ltVlCfI",
    "outputId": "e1f64381-519f-4dc6-8da0-8f3525012219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
      "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
      "apex is required for mixed precision training\n"
     ]
    }
   ],
   "source": [
    "import colossalai\n",
    "from colossalai.engine import Engine, NoPipelineSchedule\n",
    "from colossalai.trainer import Trainer\n",
    "from colossalai.context import Config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VovSqz-oSYCx"
   },
   "source": [
    "First, we should initialize distributed environment. Though we just use single GPU in this example, we still need initialize distributed environment for compatibility. We just consider the simplest case here, so we just set the number of parallel processes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-N47_xStlGsN",
    "outputId": "d796a18b-b645-4003-991b-b89081adb312"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,596 INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,598 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,602 INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,610 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,611 INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "colossalai - torch.distributed.distributed_c10d - 2021-12-09 18:33:08,615 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process rank 0 is bound to device 0\n"
     ]
    }
   ],
   "source": [
    "parallel_cfg = Config(dict(parallel=dict(\n",
    "    data=dict(size=1),\n",
    "    pipeline=dict(size=1),\n",
    "    tensor=dict(size=1, mode=None),\n",
    ")))\n",
    "colossalai.init_dist(config=parallel_cfg,\n",
    "          local_rank=0,\n",
    "          world_size=1,\n",
    "          host='127.0.0.1',\n",
    "          port=8888,\n",
    "          backend='nccl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKj6LLITP8yo"
   },
   "source": [
    "Using transfer learning on Resnet50 and creating a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-X7bbIKdlP5j"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, train_CNN=False, num_classes=1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.train_CNN = train_CNN\n",
    "        # self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
    "        # self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)\n",
    "\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet50(images)\n",
    "        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tW8EfNjdlQxg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2vLMqsZQHgE"
   },
   "source": [
    "Doing data augmentation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f5aq8zkKmCIO"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((356, 356)),\n",
    "            transforms.RandomCrop((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ckw799OPmFx6"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "train_CNN = False\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "pin_memory = True\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Awb2bniQUCc"
   },
   "source": [
    "Creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZxQdVEkVmKwN"
   },
   "outputs": [],
   "source": [
    "dataset = CatsAndDogsDataset(\"/content/drive/MyDrive/Colab Notebooks/Train/train\",\"train_csv.csv\",transform=transform)\n",
    "\n",
    "train_set, validation_set = torch.utils.data.random_split(dataset,[20000,5000])\n",
    "train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n",
    "validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "LK6AWx0AmS2s"
   },
   "outputs": [],
   "source": [
    "model = CNN().cuda()\n",
    "\n",
    "for name, param in model.resnet50.named_parameters():\n",
    "    if \"fc.weight\" in name or \"fc.bias\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = train_CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ6MPikkSu8Z"
   },
   "source": [
    "Define a Loss function and optimizer. And then we use them to initialize Engine and Trainer. We provide various training / evaluating hooks. In this case, we just use the simplest hooks which can compute and print loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xHwDCY_mYUt",
    "outputId": "b405393c-7a61-4740-a43c-267f4da3d451"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - rank_0 - 2021-12-09 22:14:30,020 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
      "colossalai - rank_0 - 2021-12-09 22:14:30,024 INFO: build LogMetricByEpochHook for train, priority = 1\n",
      "colossalai - rank_0 - 2021-12-09 22:14:30,028 INFO: build LossHook for train, priority = 10\n",
      "colossalai - rank_0 - 2021-12-09 22:14:30,030 INFO: build AccuracyHook for train, priority = 10\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "schedule = NoPipelineSchedule()\n",
    "\n",
    "engine = Engine(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=None,\n",
    "        schedule=schedule\n",
    "    )\n",
    "trainer = Trainer(engine=engine,\n",
    "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HIU20QwQyF4"
   },
   "source": [
    "Easily training on a GPU using ColossalAI which doesn't require much change from normal pytorch coding practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzyOmjP9mbjN",
    "outputId": "e25c980e-eac1-4c09-e184-f71007de346f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0 train]: 100%|██████████| 20000/20000 [09:48<00:00, 33.99it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:24:21,380 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.69329\n",
      "[Epoch 0 val]: 100%|██████████| 5000/5000 [02:16<00:00, 36.71it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:26:37,669 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.69581, Accuracy = 0.51040\n",
      "[Epoch 1 train]: 100%|██████████| 20000/20000 [09:49<00:00, 33.92it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:36:27,366 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.69329\n",
      "[Epoch 1 val]: 100%|██████████| 5000/5000 [02:16<00:00, 36.73it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:38:43,603 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.69293, Accuracy = 0.51040\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "test_interval = 1\n",
    "trainer.fit(\n",
    "        train_dataloader=train_loader,\n",
    "        test_dataloader=validation_loader,\n",
    "        max_epochs=num_epochs,\n",
    "        display_progress=True,\n",
    "        test_interval=test_interval\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEGAC88JJgsy",
    "outputId": "62f6ef59-26b0-4512-b46c-bb71ae89cdc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - rank_0 - 2021-12-09 21:48:19,855 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
      "colossalai - rank_0 - 2021-12-09 21:48:19,860 INFO: build LogMetricByEpochHook for train, priority = 1\n",
      "colossalai - rank_0 - 2021-12-09 21:48:19,862 INFO: build LossHook for train, priority = 10\n",
      "colossalai - rank_0 - 2021-12-09 21:48:19,863 INFO: build AccuracyHook for train, priority = 10\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "schedule = NoPipelineSchedule()\n",
    "\n",
    "engine = Engine(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=None,\n",
    "        schedule=schedule\n",
    "    )\n",
    "trainer = Trainer(engine=engine,\n",
    "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzaVwJFjJzXF",
    "outputId": "58a2431f-e0a7-4879-e59e-2f0bc87783ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0 train]: 100%|██████████| 20000/20000 [09:48<00:00, 34.01it/s]\n",
      "colossalai - rank_0 - 2021-12-09 21:58:11,553 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.69329\n",
      "[Epoch 0 val]:  18%|█▊        | 920/5000 [00:25<01:51, 36.64it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff604c469e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[Epoch 0 val]: 100%|██████████| 5000/5000 [02:16<00:00, 36.66it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:00:28,045 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.69320, Accuracy = 0.51040\n",
      "[Epoch 1 train]:   4%|▍         | 844/20000 [00:24<09:19, 34.21it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff604c469e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "[Epoch 1 train]:   4%|▍         | 848/20000 [00:25<09:45, 32.72it/s]    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[Epoch 1 train]: 100%|██████████| 20000/20000 [09:49<00:00, 33.94it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:10:17,433 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.69329\n",
      "[Epoch 1 val]:  19%|█▉        | 944/5000 [00:25<01:50, 36.64it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff604c469e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[Epoch 1 val]: 100%|██████████| 5000/5000 [02:16<00:00, 36.67it/s]\n",
      "colossalai - rank_0 - 2021-12-09 22:12:33,894 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.69321, Accuracy = 0.51040\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "test_interval = 1\n",
    "trainer.fit(\n",
    "        train_dataloader=train_loader,\n",
    "        test_dataloader=validation_loader,\n",
    "        max_epochs=num_epochs,\n",
    "        display_progress=True,\n",
    "        test_interval=test_interval\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFN-pi_wSMLS"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DogsVcat_inceptionCNN(transfer_learning).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
