{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DogsVcat-inceptionCNN(transfer learning).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "m"
      ],
      "metadata": {
        "id": "a9E-WWpwL_wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of ColossalAI applied on an external dataset\n"
      ],
      "metadata": {
        "id": "AcbTmhFY-oVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the dataset\n",
        "\n",
        "Kindly download the train.zip from https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "\n",
        "And create Train directory in Colab Notebooks directory\n",
        "or import dataset and change code accordingly\n"
      ],
      "metadata": {
        "id": "RX2kU5mFMMMw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkqlxsIAkGgY",
        "outputId": "baada4ca-84c9-4b98-99dc-ea1033d9b00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzipping train.zip\n"
      ],
      "metadata": {
        "id": "OA7BA5XLO4Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/train.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/Train/\""
      ],
      "metadata": {
        "id": "0NT0EkNDkQY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "\n",
        "train_df = pd.DataFrame(columns=[\"img_name\",\"label\"])\n",
        "train_df[\"img_name\"] = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Train/train/\")\n",
        "for idx, i in enumerate(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Train/train/\")):\n",
        "    if \"cat\" in i:\n",
        "        train_df[\"label\"][idx] = 0\n",
        "    if \"dog\" in i:\n",
        "        train_df[\"label\"][idx] = 1\n",
        "\n",
        "train_df.to_csv (r'train_csv.csv', index = False, header=True)"
      ],
      "metadata": {
        "id": "aNzFg8kIkru4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "created train.csv containg the image title along with label"
      ],
      "metadata": {
        "id": "zyyBFTqwPNwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "1c0jNo33k4VD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = pd.read_csv(annotation_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.annotations.iloc[index, 0]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
        "        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n",
        "       \n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        # print(img.dtype)\n",
        "        # print(y_label.dtype)\n",
        "        img = np.asarray(np.copy(img), dtype='float32')\n",
        "        label = np.asarray(np.copy(y_label), dtype='float32')\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        # Load the data into PyTorch tensors\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label)\n",
        "        targets = label.view(1)\n",
        "        return (img, targets)"
      ],
      "metadata": {
        "id": "0V5SOaKXk-kB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the custom dataset\n"
      ],
      "metadata": {
        "id": "ENo32tZNPdW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ColossalAI deepspeed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPtAbM3Ak_uB",
        "outputId": "add20223-ed60-405e-c8ae-de9a240e6ba0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ColossalAI\n",
            "  Downloading colossalai-0.0.1b0-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 12.7 MB/s \n",
            "\u001b[?25hCollecting deepspeed\n",
            "  Downloading deepspeed-0.5.8.tar.gz (517 kB)\n",
            "\u001b[K     |████████████████████████████████| 517 kB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (0.11.1+cu111)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (4.62.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ColossalAI) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->ColossalAI) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9->ColossalAI) (7.1.2)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 49.0 MB/s \n",
            "\u001b[?25hCollecting hjson\n",
            "  Downloading hjson-3.0.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting triton\n",
            "  Downloading triton-1.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ColossalAI) (3.0.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->ColossalAI) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->ColossalAI) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from triton->deepspeed) (3.4.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.8-py3-none-any.whl size=532153 sha256=88858780f9542c7783acb9289b8cb62d5f5472044bdb336c80927e523e1bba1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/c6/82/cabd9a300c582a221591fd2c8c997e1f03f601e748aad44e4e\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: triton, tensorboardX, ninja, hjson, deepspeed, ColossalAI\n",
            "Successfully installed ColossalAI-0.0.1b0 deepspeed-0.5.8 hjson-3.0.2 ninja-1.10.2.3 tensorboardX-2.4.1 triton-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colossalai\n",
        "from colossalai.engine import Engine, NoPipelineSchedule\n",
        "from colossalai.trainer import Trainer\n",
        "from colossalai.context import Config\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shzs8ltVlCfI",
        "outputId": "dd625007-eb7a-49eb-f85f-6ec7238f8643"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
            "Colossalai should be built with cuda extension to use the FP16 optimizer\n",
            "apex is required for mixed precision training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we should initialize distributed environment. Though we just use single GPU in this example, we still need initialize distributed environment for compatibility. We just consider the simplest case here, so we just set the number of parallel processes to 1."
      ],
      "metadata": {
        "id": "VovSqz-oSYCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_cfg = Config(dict(parallel=dict(\n",
        "    data=dict(size=1),\n",
        "    pipeline=dict(size=1),\n",
        "    tensor=dict(size=1, mode=None),\n",
        ")))\n",
        "colossalai.init_dist(config=parallel_cfg,\n",
        "          local_rank=0,\n",
        "          world_size=1,\n",
        "          host='127.0.0.1',\n",
        "          port=8888,\n",
        "          backend='nccl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N47_xStlGsN",
        "outputId": "5d7f4b07-246d-49f0-d017-27076257d12a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,467 INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,469 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,470 INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,476 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,480 INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
            "colossalai - torch.distributed.distributed_c10d - 2021-12-07 20:35:20,484 INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process rank 0 is bound to device 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using transfer learning on inceptionV3 and creating a CNN model"
      ],
      "metadata": {
        "id": "cKj6LLITP8yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, train_CNN=False, num_classes=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.train_CNN = train_CNN\n",
        "        self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.inception(images)\n",
        "        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)"
      ],
      "metadata": {
        "id": "-X7bbIKdlP5j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "tW8EfNjdlQxg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing data augmentation and normalization"
      ],
      "metadata": {
        "id": "K2vLMqsZQHgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((356, 356)),\n",
        "            transforms.RandomCrop((299, 299)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "f5aq8zkKmCIO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.00001\n",
        "train_CNN = False\n",
        "batch_size = 1\n",
        "shuffle = True\n",
        "pin_memory = True\n",
        "num_workers = 1"
      ],
      "metadata": {
        "id": "Ckw799OPmFx6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dataloader"
      ],
      "metadata": {
        "id": "6Awb2bniQUCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CatsAndDogsDataset(\"/content/drive/MyDrive/Colab Notebooks/Train/train\",\"train_csv.csv\",transform=transform)\n",
        "\n",
        "train_set, validation_set = torch.utils.data.random_split(dataset,[20000,5000])\n",
        "train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n",
        "validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)"
      ],
      "metadata": {
        "id": "ZxQdVEkVmKwN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().cuda()\n",
        "\n",
        "for name, param in model.inception.named_parameters():\n",
        "    if \"fc.weight\" in name or \"fc.bias\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = train_CNN\n"
      ],
      "metadata": {
        "id": "LK6AWx0AmS2s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Loss function and optimizer. And then we use them to initialize Engine and Trainer. We provide various training / evaluating hooks. In this case, we just use the simplest hooks which can compute and print loss and accuracy."
      ],
      "metadata": {
        "id": "KZ6MPikkSu8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "schedule = NoPipelineSchedule()\n",
        "\n",
        "engine = Engine(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=None,\n",
        "        schedule=schedule\n",
        "    )\n",
        "trainer = Trainer(engine=engine,\n",
        "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
        "          verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xHwDCY_mYUt",
        "outputId": "3dd6cdb6-ef75-4474-9c9c-6be729c4386d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - rank_0 - 2021-12-07 22:17:24,328 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
            "colossalai - rank_0 - 2021-12-07 22:17:24,331 INFO: build LogMetricByEpochHook for train, priority = 1\n",
            "colossalai - rank_0 - 2021-12-07 22:17:24,333 INFO: build LossHook for train, priority = 10\n",
            "colossalai - rank_0 - 2021-12-07 22:17:24,337 INFO: build AccuracyHook for train, priority = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easily training on a GPU using ColossalAI which doesn't require much change from normal pytorch coding practices"
      ],
      "metadata": {
        "id": "2HIU20QwQyF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "test_interval = 1\n",
        "trainer.fit(\n",
        "        train_dataloader=train_loader,\n",
        "        test_dataloader=validation_loader,\n",
        "        max_epochs=num_epochs,\n",
        "        display_progress=True,\n",
        "        test_interval=test_interval\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzyOmjP9mbjN",
        "outputId": "d91a4283-1dee-4946-ec84-e82d0a1f0506"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 0 train]: 100%|██████████| 20000/20000 [12:12<00:00, 27.32it/s]\n",
            "colossalai - rank_0 - 2021-12-07 22:29:54,685 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.69350\n",
            "[Epoch 0 val]: 100%|██████████| 5000/5000 [02:47<00:00, 29.91it/s]\n",
            "colossalai - rank_0 - 2021-12-07 22:32:41,957 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.69314, Accuracy = 0.49960\n",
            "[Epoch 1 train]: 100%|██████████| 20000/20000 [12:09<00:00, 27.42it/s]\n",
            "colossalai - rank_0 - 2021-12-07 22:44:51,541 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.69332\n",
            "[Epoch 1 val]: 100%|██████████| 5000/5000 [02:46<00:00, 29.95it/s]\n",
            "colossalai - rank_0 - 2021-12-07 22:47:38,571 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.69312, Accuracy = 0.49960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# criterion = nn.BCELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "schedule = NoPipelineSchedule()\n",
        "\n",
        "engine = Engine(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        lr_scheduler=None,\n",
        "        schedule=schedule\n",
        "    )\n",
        "trainer = Trainer(engine=engine,\n",
        "          hooks_cfg=[dict(type='LossHook'), dict(type='LogMetricByEpochHook'), dict(type='AccuracyHook')],\n",
        "          verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEGAC88JJgsy",
        "outputId": "48cadbc1-e610-44a5-95b0-719e7fd8f4c3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "colossalai - rank_0 - 2021-12-07 23:08:57,510 WARNING: No gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
            "colossalai - rank_0 - 2021-12-07 23:08:57,514 INFO: build LogMetricByEpochHook for train, priority = 1\n",
            "colossalai - rank_0 - 2021-12-07 23:08:57,515 INFO: build LossHook for train, priority = 10\n",
            "colossalai - rank_0 - 2021-12-07 23:08:57,518 INFO: build AccuracyHook for train, priority = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "test_interval = 1\n",
        "trainer.fit(\n",
        "        train_dataloader=train_loader,\n",
        "        test_dataloader=validation_loader,\n",
        "        max_epochs=num_epochs,\n",
        "        display_progress=True,\n",
        "        test_interval=test_interval\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzaVwJFjJzXF",
        "outputId": "b97449c6-947f-4aea-a144-221331e204fc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 0 train]: 100%|██████████| 20000/20000 [12:07<00:00, 27.48it/s]\n",
            "colossalai - rank_0 - 2021-12-07 23:21:08,658 INFO: Training - Epoch 1 - LogMetricByEpochHook: Loss = 0.69329\n",
            "[Epoch 0 val]: 100%|██████████| 5000/5000 [02:47<00:00, 29.80it/s]\n",
            "colossalai - rank_0 - 2021-12-07 23:23:56,564 INFO: Testing - Epoch 1 - LogMetricByEpochHook: Loss = 0.69313, Accuracy = 0.49960\n",
            "[Epoch 1 train]: 100%|██████████| 20000/20000 [12:08<00:00, 27.47it/s]\n",
            "colossalai - rank_0 - 2021-12-07 23:36:04,713 INFO: Training - Epoch 2 - LogMetricByEpochHook: Loss = 0.69329\n",
            "[Epoch 1 val]: 100%|██████████| 5000/5000 [02:47<00:00, 29.88it/s]\n",
            "colossalai - rank_0 - 2021-12-07 23:38:52,144 INFO: Testing - Epoch 2 - LogMetricByEpochHook: Loss = 0.69313, Accuracy = 0.49960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QFN-pi_wSMLS"
      }
    }
  ]
}